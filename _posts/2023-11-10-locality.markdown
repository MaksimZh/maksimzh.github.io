---
layout: post
title:  "Локальная и нелокальная трансляция"
date:   2023-11-10
---

В [предыдущем посте]({% post_url 2023-11-07-factorial %})
нам понадобилось ленивое вычисление веток оператора `if`:

![рекурсивная версия факториала](/assets/fac-rec.png)

Ветка `false` должна вычисляться только когда она действительно нужна
(в зависимости от значения `cond`),
иначе рекурсия будет бесконечной.

Что если наша программа транслировалась бы, например, на язык C,
и оператор `if` был реализован в виде функции?
```C
int if_func(bool cond, int true_val, int false_val) {
    if (cond)
        return true_val;
    return false_val;
}
```
Все аргументы такой функции должны быть вычислены до её вызова,
а значит рекурсия выйдет из под контроля.
До `if` дело даже не дойдёт.

Дело в том, что компилятор обрабатывает функции независимо от кода,
который их вызывает, и наоборот: для вызывающего кода функция - чёрный ящик.
Можно сказать, что компиляция происходит **локально**: внутри функции,
внутри модуля, или даже внутри отдельного выражения (statement).
В случае ассемблера трансляция может происходить даже внутри одной инструкции.

Может ли трансляция быть **нелокальной**?
Да! Чаще всего нелокальность используется для оптимизации.
Один из примеров - встраиваемые (inline) функции, код которых
"вставляется" в код вызывающей функции вместо вызова.
После этого уже нет функции и вызова, только код, и после оптимизации
можно и не догадаться, что функция вообще была.
В этом случае компилятор "залезает" внутрь функции при анализе внешнего кода.

Обратный пример -
[ленивые аргументы функций в языке D](https://dlang.org/articles/lazy-evaluation.html):
```D
int if_func(bool cond, lazy int true_val, lazy int false_val) {
    if (cond)
        return true_val;
    return false_val;
}
```
Технически, в этом случае в `if_func` передаются
**не результаты** вычисления аргументов,
**а функции** для вычисления аргументов, которые можно вызывать,
а можно не вызывать.
По логике выполнения программы получается,
что мы "втянули" часть вызывающего кода внутрь нашей функции.

В случае оператора `if` в нашем примере нелокальность - это не инструмент
оптимизации, а жизненная необходимость.
Если разрабатывать транслятор для такого графического языка программирования,
то он должен быть нелокальным.
Условный оператор может прятаться внутри других процедур,
и для которых вычисление некоторых из входных значений может не потребоваться.

Может показаться, что этот механизм усложняет не только транслятор,
но и рассуждения о программе.
Теперь ведь нужно всегда держать в голове возможность того, что какие то
ветки на нашей диаграмме не будут выполнены, причём эти ветки могут быть
даже не помечены явно оператором `if`.

Решение очень простое.
В голове нужно держать не механизм выполнения кода, а логику программы.
Из-за того, что изучение программирования для большинства из нас начинается
с императивного подхода (в моём случае это был язык Pascal),
логика у нас загрязнена.
Когда мы думаем о программировании, то автоматически подразумеваем состояния
и передачу управления.
Нам кажется, что это и есть логика программы, но это вовсе не обязательно.

В математике логика декларативна, а не императивна.
Доказательства теорем не выполняются, не глючат,
не переполняют стек, не выбрасывают исключений
(хотя, всё это вполне может происходить с ПО для
интерактивного доказательства теорем).

Посмотрим на рисунок ещё раз:

![рекурсивная версия факториала](/assets/fac-rec.png)

Здесь нет потока исполнения, нет предачи управления, нет вызовов функций.
Пока у нас нет стека, нам не грозит его переполнение,
а значит **нам** не нужно думать про стек.
Пусть компилятор про стек думает.
Если у него получится сделать
[хвостовую рекурсию](https://ru.wikipedia.org/wiki/%D0%A5%D0%B2%D0%BE%D1%81%D1%82%D0%BE%D0%B2%D0%B0%D1%8F_%D1%80%D0%B5%D0%BA%D1%83%D1%80%D1%81%D0%B8%D1%8F),
то стек в таких объёмах не понадобится.

Можно рассматривать программу, как логическую задачу для компилятора:

> Найди последовательность команд для компьютера,
которая для каждого `n` найдёт `result`, удовлетворяющей этой схеме,
за конечное время, и используя конечный объём памяти.

Создать компилятор, который справляется с такими задачами,
означает **автоматизировать то, что мы по привычке считаем программированием**.
Я слышал, что разработчики Haskell прошли по этому пути довольно далеко.

Наша программа - это логические блоки,
у которых есть входные и выходные значения, связываемые друг с другом.
Вполне возможно рассуждать о корректности кода уже на этом этапе,
не вдаваясь в детали выполнения.
Здесь мы даже ближе к формальному математическому определению факториала:
```
n! := { 1,            n < 2
      { n * (n - 1)!, n >= 2
```

Чувствую, что здесь граница между математикой и программированием стирается.
Можно ли записывать математические определения и доказательства теорем
таким же многомерным графическим способом?
Может тогда математика будет восприниматься по-другому?
